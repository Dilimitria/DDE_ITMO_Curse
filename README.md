# Обработка данных покупателей онлайн платформы

## Цель проекта
Создание автоматизированного ETL-пайплайна для обработки транзакционных данных и проведения глубокого анализа клиентской базы (RFM, ABC, Cohort Analysis) с целью оптимизации маркетинговых стратегий.

## Датасет
В проекте используется набор данных о транзакциях интернет-магазина (Online Retail Dataset), включающий историю покупок клиентов из разных стран за годовой период.

# Руководство по работе с проектом

## Структура проекта
```
online-retail-analytics/
├── etl/                # Скрипты обработки данных
│   ├── flows.py        # Основной пайплайн (Prefect)
│   ├── database.py     # Логика работы с БД
│   ├── rfm_processor.py# Алгоритмы сегментации
│   └── config.py       # Настройки путей
├── notebooks/          # Исследовательский анализ
│   └── EDA.ipynb       # Итоговый отчет с графиками
├── data/               # База данных и сырые файлы
│   └── data.txt        # Указана ссылка на гугл диск с сырыми данными
├── requirements.txt    # Зависимости проекта
├── .env.example        # Шаблон конфигурации окружения
└── README.md           # Документация
```

# Подготовка окружения
## 1. Создание виртуального окружения
```powershell
python -m venv .venv
.\.venv\Scripts\activate
```

## 2. Установка зависимостей
```
pip install -r requirements.txt
```
## 3. Запуск ETL-процесса
Выполнить команду в терминале:
```
python main.py
```
После запуска скрипт выполняет архитектурное разделение данных на слои:

## 1. Слой Silver (Очистка)
Данные сохраняются в таблицу cleaned_transactions:

Удаление записей без CustomerID.

Преобразование типов данных (InvoiceDate -> datetime).

Расчет итоговой стоимости (Total_Price).

Очистка от дубликатов и системных ошибок.

## 2. Слой Gold (Аналитические витрины)
На основе очищенных данных формируются итоговые таблицы:

mart_customer_segments: результаты RFM-анализа (Recency, Frequency, Monetary).

mart_countries_abc: классификация рынков сбыта по доле в выручке.

audit_order_anomalies: выявленные подозрительные транзакции.

# Исследовательский анализ (EDA)
После формирования базы данных откройте ноутбук notebooks/EDA.ipynb. В нем реализованы следующие ключевые отчеты:

## 1. Когортный анализ (Retention)
Визуализация удержания клиентов в виде тепловой карты (Heatmap) по месяцам. Позволяет определить "жизненный цикл" клиента и критические точки оттока.

## 2. Качество данных и аномалии
Анализ пропущенных значений через seaborn.heatmap.

## 3. Сегментация и инсайты
Распределение клиентов по RFM-категориям.

Выявление сегмента "At Risk" (под угрозой ухода) для таргетированных рассылок.

# Результаты оптимизации
Благодаря внедрению слоев данных в SQLite:

## Скорость анализа: 
Чтение готовой витрины происходит в 10 раз быстрее, чем обработка сырого CSV.

## Гибкость: 
Возможность проводить сегментацию по любому срезу данных (время, страна, товар).

## Масштабируемость: 
Пайплайн на Prefect позволяет легко добавлять новые этапы обработки.
